# multilayer-perceptron

https://medium.com/@omkar.nallagoni/activation-functions-with-derivative-and-python-code-sigmoid-vs-tanh-vs-relu-44d23915c1f4

http://neuralnetworksanddeeplearning.com/chap2.html

https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e

https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/

https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/

https://stats.stackexchange.com/questions/201569/what-is-the-difference-between-dropout-and-drop-connect



