# multilayer-perceptron


https://medium.com/@omkar.nallagoni/activation-functions-with-derivative-and-python-code-sigmoid-vs-tanh-vs-relu-44d23915c1f4

http://neuralnetworksanddeeplearning.com/chap2.html

https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e

https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/

https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/

https://stats.stackexchange.com/questions/201569/what-is-the-difference-between-dropout-and-drop-connect

https://www.machinecurve.com/index.php/2019/09/16/he-xavier-initialization-activation-functions-choose-wisely/


https://www.quora.com/What-is-an-intuitive-explanation-of-momentum-in-training-neural-networks


